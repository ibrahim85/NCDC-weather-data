{
 "metadata": {
  "name": "",
  "signature": "sha256:09fb5cb97f037851c9963c692111a6ce9873f712461ee7d090e02868baf92bd1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font face='\"Lucida Console\", Monaco, monospace' color = 'navy'>\n",
      "<style>a:hover {text-decoration: underline}</style>\n",
      "    NOAA\u2019s <a href = 'http://www.ncdc.noaa.gov/' style=\"color: black; text-decoration: none\" >National Climatic Data Center (NCDC)</a> maintains the world's largest climate data archive and provides <a href = 'http://www.ncdc.noaa.gov/data-access/quick-links' style=\"color: black; text-decoration: none\" >climate and weather datasets</a> to the users worldwide.  <br /> <br />\n",
      "For this project, we'll look at two of their datasets \n",
      "<ul><li> Global Historical Climatology Network-Daily  (GHCN-D) </li>\n",
      "<li> Global Summary of the Day  (GSOD) </li></ul> <br /> \n",
      "We'll analyze and compare the ditribution of the recordings temporally and spatially. \n",
      "</font> "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Importing all the required modules\n",
      "\n",
      "import os, sys, numpy, base64, zlib, pickle\n",
      "import pandas as pd\n",
      "import cPickle as cpkl\n",
      "from scipy.sparse import *\n",
      "from scipy import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "home_dir='/home/ubuntu/UCSD_BigData'\n",
      "sys.path.append(home_dir+'/utils')\n",
      "\n",
      "# Importing some functions necessary for MRjobs\n",
      "from find_waiting_flow import *\n",
      "from AWS_keypair_management import *\n",
      "\n",
      "cur_dir  = home_dir+'/notebooks/weather_project' #working directory"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Loading required credentials and creating Config file for mrjob\n",
      "\n",
      "Creds= pickle.load(open('/home/ubuntu/Vault/Creds.pkl','rb'))\n",
      "pair=Creds['mrjob']\n",
      "key_id=pair['key_id']\n",
      "secret_key=pair['secret_key']\n",
      "ID=pair['ID']\n",
      "\n",
      "%cd $home_dir/utils/\n",
      "!python Make.mrjob.conf.py  #If EC2_VAULT is not defined, default location - '/home/ubuntu/Vault'\n",
      "%cd $home_dir/notebooks/weather_project"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/ubuntu/UCSD_BigData/utils\n",
        "Created the configuration file: /home/ubuntu/.mrjob.conf\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/ubuntu/UCSD_BigData/notebooks/weather_project\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font face='\"Lucida Console\", Monaco, monospace' color = 'navy'>\n",
      "Importing functions  </font>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from functions_weather import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile functions_weather.py\n",
      "#define all the functions here\n",
      "import os, sys, numpy, base64, zlib, pickle\n",
      "import pandas as pd\n",
      "\n",
      "def loads(eVal):\n",
      "    \"\"\" Decode a string into a value \"\"\"\n",
      "    return pickle.loads(zlib.decompress(base64.b64decode(eVal)))\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting functions_weather.py\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "<font color = 'maroon'>1. Global Historical Climatology Network-Daily Dataset (GHCN-D) </font>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font face='\"Lucida Console\", Monaco, monospace' color = 'navy'>\n",
      "The <a href = 'http://www1.ncdc.noaa.gov/pub/data/ghcn/daily/' style=\"color: black; text-decoration: none\" >GHCN-Daily dataset</a> contains daily climate records from over 80,000 stations worldwide. <br /> <br />\n",
      "\n",
      "The dataset includes five core readings :<br />\n",
      "1. Precipitation (PRCP)<br />\n",
      "2. Snowfall (SNOW) <br />\n",
      "3. Snow depth (SNWD) <br />\n",
      "4. Maximum temperature (TMAX)<br />\n",
      "5. Minimum temperature (TMIN)<br /> <br /> \n",
      "A typical single line in the data file has the following format<br />\n",
      "<b>Station ID, Measurement, Year, [readings for 365 days starting from January 1st (the last day of leap years is discarded)]</b>\n",
      "\n",
      "</font>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print a random line from the file\n",
      "#We Believe in Randomness\n",
      "\n",
      "!shuf -n1 ALL.csv_1024 "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "USC00442155,TMAX,1926,111,128,106,83,139,139,44,6,28,11,33,33,0,0,72,39,61,89,139,178,117,117,28,61,0,22,72,72,-11,50,89,61,83,44,56,33,61,,,,,,44,100,83,94,72,133,106,122,94,183,200,144,139,167,139,56,50,117,72,28,39,-11,61,144,94,56,139,61,44,22,56,72,83,94,139,206,244,133,172,172,239,272,189,106,94,156,183,122,100,167,200,156,228,172,228,233,161,200,150,83,56,189,194,222,194,128,72,139,261,294,239,278,211,189,189,156,189,300,322,267,283,172,200,256,311,294,256,222,211,233,289,250,244,183,289,300,294,261,239,272,200,239,256,233,222,200,211,250,289,294,278,256,200,128,178,239,294,294,289,294,311,311,339,317,189,189,294,283,228,272,300,244,244,283,283,228,272,311,339,294,311,283,289,239,311,300,311,344,356,328,272,306,261,222,272,300,333,317,356,383,383,339,306,294,278,233,250,267,311,289,306,322,339,317,317,317,311,289,289,317,356,356,350,356,278,322,306,256,233,183,189,217,233,261,239,256,289,289,328,289,261,278,311,206,183,239,278,261,267,322,211,228,278,272,189,222,261,222,200,261,289,283,256,300,283,322,233,144,156,200,172,183,250,294,300,294,233,183,178,161,228,217,156,217,206,206,156,183,211,172,133,133,167,128,128,156,156,117,167,244,233,167,106,100,78,100,56,144,167,144,239,172,22,72,122,194,189,189,139,106,100,50,33,61,117,111,144,144,106,33,128,100,89,44,44,44,33,17,11,150,100,17,,56,72,72,17,-11,28,0,-11,44,78,56,11,67,83,61,39,17,50,17,61\r\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Station Details"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font face='\"Lucida Console\", Monaco, monospace' color = 'navy'>\n",
      "Read Station Data into Pandas Dataframe\n",
      "</font>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#loading data corresponding to station IDs \n",
      "!gunzip stations.pkl.gz\n",
      "GHCN_Stations=pickle.load(open('stations.pkl', 'rb'))\n",
      "!gzip stations.pkl\n",
      "\n",
      "GHCN_Stations.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>latitude</th>\n",
        "      <th>longitude</th>\n",
        "      <th>elevation</th>\n",
        "      <th>state</th>\n",
        "      <th>name</th>\n",
        "      <th>GSNFLAG</th>\n",
        "      <th>HCNFLAG</th>\n",
        "      <th>WMOID</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>ACW00011604</th>\n",
        "      <td> 17.1167</td>\n",
        "      <td>-61.7833</td>\n",
        "      <td>   10.1</td>\n",
        "      <td> NaN</td>\n",
        "      <td> ST JOHNS COOLIDGE FLD</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>   NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>ACW00011647</th>\n",
        "      <td> 17.1333</td>\n",
        "      <td>-61.7833</td>\n",
        "      <td>   19.2</td>\n",
        "      <td> NaN</td>\n",
        "      <td>              ST JOHNS</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>   NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AE000041196</th>\n",
        "      <td> 25.3330</td>\n",
        "      <td> 55.5170</td>\n",
        "      <td>   34.0</td>\n",
        "      <td> NaN</td>\n",
        "      <td>   SHARJAH INTER. AIRP</td>\n",
        "      <td> GSN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 41196</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AF000040930</th>\n",
        "      <td> 35.3170</td>\n",
        "      <td> 69.0170</td>\n",
        "      <td> 3366.0</td>\n",
        "      <td> NaN</td>\n",
        "      <td>          NORTH-SALANG</td>\n",
        "      <td> GSN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 40930</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AG000060390</th>\n",
        "      <td> 36.7167</td>\n",
        "      <td>  3.2500</td>\n",
        "      <td>   24.0</td>\n",
        "      <td> NaN</td>\n",
        "      <td>    ALGER-DAR EL BEIDA</td>\n",
        "      <td> GSN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 60390</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 8 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "             latitude  longitude  elevation state                   name  \\\n",
        "ACW00011604   17.1167   -61.7833       10.1   NaN  ST JOHNS COOLIDGE FLD   \n",
        "ACW00011647   17.1333   -61.7833       19.2   NaN               ST JOHNS   \n",
        "AE000041196   25.3330    55.5170       34.0   NaN    SHARJAH INTER. AIRP   \n",
        "AF000040930   35.3170    69.0170     3366.0   NaN           NORTH-SALANG   \n",
        "AG000060390   36.7167     3.2500       24.0   NaN     ALGER-DAR EL BEIDA   \n",
        "\n",
        "            GSNFLAG HCNFLAG  WMOID  \n",
        "ACW00011604     NaN     NaN    NaN  \n",
        "ACW00011647     NaN     NaN    NaN  \n",
        "AE000041196     GSN     NaN  41196  \n",
        "AF000040930     GSN     NaN  40930  \n",
        "AG000060390     GSN     NaN  60390  \n",
        "\n",
        "[5 rows x 8 columns]"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ghcn_station_details(stn):\n",
      "    if not (stn in GHCN_Stations.index):\n",
      "        print '\\n' + stn + ' - No details found / Invalid station'  \n",
      "    else:\n",
      "        stn_lat  = GHCN_Stations['latitude'][stn]\n",
      "        stn_lon  = GHCN_Stations['longitude'][stn]\n",
      "        stn_elvn = GHCN_Stations['elevation'][stn]\n",
      "        print \"Station Details for '\"+ stn + \"'\"\n",
      "        print \"\\nName      : \", GHCN_Stations['name'][stn]\n",
      "        print \"Location  : \", \n",
      "        print abs(stn_lat), u\"\\u00b0\", ('S' if stn_lat < 0 else 'N'), ',' ,\n",
      "        print abs(stn_lon), u\"\\u00b0\", ('E' if stn_lat < 0 else 'W')\n",
      "        print \"Elevation : \", ('missing' if stn_elvn == -999.9 else str(stn_elvn) + ' m')\n",
      "        print \"Google maps link : https://www.google.com/maps/place/\"+str(stn_lat)+ \",\" + str(stn_lon) +'\\n'\n",
      "    \n",
      "ghcn_station_details(\"IN011221700\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Station Details for 'IN011221700'\n",
        "\n",
        "Name      :  BIJAYPUR\n",
        "Location  :  26.05 \u00b0 N , 77.38 \u00b0 W\n",
        "Elevation :  229.0 m\n",
        "Google maps link : https://www.google.com/maps/place/26.05,77.38\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "<font color = 'maroon'>2. Global Summary of the Day Dataset (GSOD) </font>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font face='\"Lucida Console\", Monaco, monospace' color = 'navy'>\n",
      "\n",
      "Daily weather elements in the <a href = 'http://www.ncdc.noaa.gov/cgi-bin/res40.pl?page=gsod.html' style=\"color: black; text-decoration: none\" >GSOD dataset</a> include : <br /> mean temperature, mean dew point, mean sea level pressure, station mean pressure, maximum and minimum temperature, maximum sustained wind speed and maximum gust, precipitation amount, snow depth, weather indicators etc. <br /> <br />\n",
      "\n",
      "A Typical single line in the data file has the following format - <br />\n",
      "<b>STN Number, WBAN Number, YEAR-MONTH-DATE, TEMP, Count, DEWP, Count, SLP, Count, STP, Count, VISIB, Count, WDSP, Count, MXSPD, GUST, TMAX(Flag), TMIN(Flag), PRCP(Flag), SNDP, FRSHTT </b><br /> <br />\n",
      "\n",
      "'Count' is used to indicate number of observations used in calculating mean. <br />\n",
      "'Flag' is used to indicate whether the mean was calculate using explicit measurement report or from 'hourly' data. <br />\n",
      "More details about the dataset contents can be found here - <a href = \"ftp://ftp.ncdc.noaa.gov/pub/data/gsod/readme.txt\" style=\"color: black; text-decoration: none\" >ftp://ftp.ncdc.noaa.gov/pub/data/gsod/readme.txt</a>\n",
      "\n",
      "</font>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print a random line from the file\n",
      "\n",
      "!shuf -n1 gsod.all.tsv_1024"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "014270,99999,19890930,54.6,5,51.2,5,1023.9,5,9999.9,0,17.4,5,16.0,5,19.0,33.0,57.7,53.2,0.00D,999.9,000000\r\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Station Details"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font face='\"Lucida Console\", Monaco, monospace' color = 'navy'>\n",
      "Read Station Data into Pandas Dataframe\n",
      "</font>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#loading data corresponding to station IDs \n",
      "GSOD_Stations=pd.read_csv(\"ish-history.csv\", converters={'USAF': str, 'WBAN': str})\n",
      "GSOD_Stations.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>USAF</th>\n",
        "      <th>WBAN</th>\n",
        "      <th>STATION NAME</th>\n",
        "      <th>CTRY</th>\n",
        "      <th>FIPS</th>\n",
        "      <th>STATE</th>\n",
        "      <th>CALL</th>\n",
        "      <th>LAT</th>\n",
        "      <th>LON</th>\n",
        "      <th>ELEV(.1M)</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 000000</td>\n",
        "      <td> 99999</td>\n",
        "      <td>  NYGGBUKTA GREENLAND- STA</td>\n",
        "      <td> GL</td>\n",
        "      <td> GL</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 73483</td>\n",
        "      <td> 21567</td>\n",
        "      <td>  30</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 000010</td>\n",
        "      <td> 99999</td>\n",
        "      <td>                 JAN HAYEN</td>\n",
        "      <td> NO</td>\n",
        "      <td> NO</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 70983</td>\n",
        "      <td> -7700</td>\n",
        "      <td> 229</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 000020</td>\n",
        "      <td> 99999</td>\n",
        "      <td> ISFJORD RADIO SPITZBERGEN</td>\n",
        "      <td> NO</td>\n",
        "      <td> NO</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 78067</td>\n",
        "      <td> 13633</td>\n",
        "      <td>  79</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 000030</td>\n",
        "      <td> 99999</td>\n",
        "      <td>      BJORNOYA BARENTS SEA</td>\n",
        "      <td> NO</td>\n",
        "      <td> NO</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 74467</td>\n",
        "      <td> 19283</td>\n",
        "      <td> 290</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 000040</td>\n",
        "      <td> 99999</td>\n",
        "      <td>                     VAROO</td>\n",
        "      <td> NO</td>\n",
        "      <td> NO</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 70367</td>\n",
        "      <td> 31100</td>\n",
        "      <td> 119</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 10 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "     USAF   WBAN               STATION NAME CTRY FIPS STATE CALL    LAT  \\\n",
        "0  000000  99999   NYGGBUKTA GREENLAND- STA   GL   GL   NaN  NaN  73483   \n",
        "1  000010  99999                  JAN HAYEN   NO   NO   NaN  NaN  70983   \n",
        "2  000020  99999  ISFJORD RADIO SPITZBERGEN   NO   NO   NaN  NaN  78067   \n",
        "3  000030  99999       BJORNOYA BARENTS SEA   NO   NO   NaN  NaN  74467   \n",
        "4  000040  99999                      VAROO   NO   NO   NaN  NaN  70367   \n",
        "\n",
        "     LON  ELEV(.1M)  \n",
        "0  21567         30  \n",
        "1  -7700        229  \n",
        "2  13633         79  \n",
        "3  19283        290  \n",
        "4  31100        119  \n",
        "\n",
        "[5 rows x 10 columns]"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#converting latitude/longuitdes to degrees and elevation to meters\n",
      "GSOD_Stations['LAT'] = GSOD_Stations['LAT']/1000.0 \n",
      "GSOD_Stations['LON'] = GSOD_Stations['LON']/1000.0 \n",
      "if('ELEV(.1M)' in GSOD_Stations.columns):\n",
      "    GSOD_Stations['ELEV'] = GSOD_Stations['ELEV(.1M)']/10.0 \n",
      "    GSOD_Stations.drop('ELEV(.1M)',1)\n",
      "\n",
      "#set 'USAF' as the index for the dataframe\n",
      "if('USAF' in GSOD_Stations.columns):\n",
      "    GSOD_Stations = GSOD_Stations.set_index(['USAF'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def gsod_station_details(stn):\n",
      "    if not (stn in GSOD_Stations.index):\n",
      "        print '\\n' + stn + ' - No details found / Invalid station'  \n",
      "    else:\n",
      "        stn_lat  = GSOD_Stations['LAT'][stn]\n",
      "        stn_lon  = GSOD_Stations['LON'][stn]\n",
      "        stn_elvn = GSOD_Stations['ELEV'][stn]\n",
      "        print \"\\nStation Details for '\"+ stn + \"'\"\n",
      "        print \"\\nName      : \", GSOD_Stations['STATION NAME'][stn]\n",
      "        print \"Location  : \", \n",
      "        print abs(stn_lat), u\"\\u00b0\", ('S' if stn_lat < 0 else 'N'), ',' ,\n",
      "        print abs(stn_lon), u\"\\u00b0\", ('E' if stn_lat < 0 else 'W')\n",
      "        print \"Elevation : \", ('missing' if stn_elvn == -99.99 else str(stn_elvn) + ' m')\n",
      "        print \"Google maps link : https://www.google.com/maps/place/\"+str(stn_lat)+ \",\" + str(stn_lon) +'\\n'\n",
      "\n",
      "gsod_station_details(\"431170\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Station Details for '431170'\n",
        "\n",
        "Name      :  SHOLAPUR\n",
        "Location  :  17.667 \u00b0 N , 75.9 \u00b0 W\n",
        "Elevation :  479.0 m\n",
        "Google maps link : https://www.google.com/maps/place/17.667,75.9\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "<font color = 'maroon'>3. Collecting Statistics using Map Reduce</font>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font face='\"Lucida Console\", Monaco, monospace' color = 'navy'>\n",
      "For both the datasets, we collect the count of readings defined out of 365 possible days for each (measurement, year) pair whenever available.<br /> <br />\n",
      "\n",
      "To remove long and unnecessary outputs of MR job files, we have commented them out. Code can be found in the corresponding python files. \n",
      "</font>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!python collect_GHCNStats.py ALL.csv_1024 > ghcn_counts_local"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#job_flow_id=find_waiting_flow(key_id,secret_key)\n",
      "#!python collect_GHCNStats.py -r emr --emr-job-flow-id $job_flow_id s3://vineel-bucket/ALL.csv > ghcn_counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!python collect_GSODStats.py gsod.all.tsv_1024 > gsod_counts_local"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#job_flow_id=find_waiting_flow(key_id,secret_key)\n",
      "#!python collect_GSODStats.py -r emr --emr-job-flow-id $job_flow_id s3://vineel-bucket/gsod.all.tsv > gsod_counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_countsdata_to_dict(loc):\n",
      "    stn_data = {}\n",
      "    f = open(loc)\n",
      "    for line in f:\n",
      "        stn, data_enc = line.split()\n",
      "        stn_data[stn[1:-1]] = loads(data_enc[1:-1])\n",
      "    return stn_data\n",
      "\n",
      "ghcn_counts = load_countsdata_to_dict('ghcn_counts')\n",
      "gsod_counts = load_countsdata_to_dict('gsod_counts')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "<font color = 'maroon'>4. Analysis of datasets</font>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ghcn_measurements = ['TMIN', 'TMAX', 'PRCP', 'SNWD', 'SNOW'] \n",
      "gsod_measurements = ['TMIN', 'TMAX', 'PRCP', 'SNDP', 'TEMP'] "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font face='\"Lucida Console\", Monaco, monospace' color = 'navy'> \n",
      "Quick check to find the range of years for which readings are available </font>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def find_min_max_years(counts):\n",
      "    min_year, max_year = 2014, 1000  #initialize with obvious wrong values\n",
      "    for stn in counts.iterkeys():\n",
      "        for (yr,_) in counts[stn].iterkeys():\n",
      "            if(yr < min_year): min_year = yr\n",
      "            if(yr > max_year): max_year = yr\n",
      "    return (min_year, max_year)\n",
      "\n",
      "ghcn_min_year, ghcn_max_year = find_min_max_years(ghcn_counts)\n",
      "gsod_min_year, gsod_max_year = find_min_max_years(gsod_counts)\n",
      "\n",
      "ghcn_range_years = ghcn_max_year -  ghcn_min_year + 1\n",
      "gsod_range_years = gsod_max_year -  gsod_min_year + 1\n",
      "\n",
      "\n",
      "print 'Readings avaialble for GHCN-D between the years:', ghcn_min_year, '-', ghcn_max_year ,'; Range  : ' ,\\\n",
      "                                                                                                ghcn_range_years, ' years'\n",
      "print 'Readings avaialble for  GSOD  between the years:', gsod_min_year, '-', gsod_max_year ,'; Range  : ' , \\\n",
      "                                                                                                gsod_range_years, ' years'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Readings avaialble for GHCN-D between the years: 1763 - 2013 ; Range  :  251  years\n",
        "Readings avaialble for  GSOD  between the years: 1929 - 2009 ; Range  :  81  years\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font face='\"Lucida Console\", Monaco, monospace' color = 'navy'> \n",
      "Now, we'll take a look if we have information for all the stations \n",
      "</font>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def stations_absent(counts, Stations):\n",
      "    cnt = 0\n",
      "    data = []\n",
      "    for stn in counts.iterkeys():\n",
      "        if not (stn in Stations.index):\n",
      "            cnt +=1 \n",
      "            data.append(stn)\n",
      "    return (data, cnt)\n",
      "\n",
      "ghcn_stations_absent, ghcn_stations_absent_count = stations_absent (ghcn_counts, GHCN_Stations)\n",
      "gsod_stations_absent, gsod_stations_absent_count = stations_absent (gsod_counts, GSOD_Stations)\n",
      "\n",
      "print 'Unavailable GHCN-D station data - ', ghcn_stations_absent_count\n",
      "print 'Unavailable  GSOD  station data - ', gsod_stations_absent_count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Unavailable GHCN-D station data -  0\n",
        "Unavailable  GSOD  station data -  36\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font face='\"Lucida Console\", Monaco, monospace' color = 'navy'> \n",
      "GSOD station list made available at <a href = 'ftp://ftp.ncdc.noaa.gov/pub/data/inventories/ISH-HISTORY.TXT' style=\"color: black; text-decoration: none\" > ftp://ftp.ncdc.noaa.gov/pub/data/inventories/ISH-HISTORY.TXT </a> doesn't have a few stations' (~1000) data available.\n",
      "We map the stations for which data is not available to their approximate location. We keep a flag = 1 in the GSOD station dataframe for these stations.  <br /> <br />\n",
      "<u><font color='black'>Approximating GSOD station locations for unavailable data:</font></u> <br />\n",
      "    USAF number is used a station ID for GSOD data. It has the format 'xxyyyz' where first 5-digits constitute the 5-digit World Meteorological Organization (WMO) ID ('xx' - block number, 'yyy' - station number) and 'z' $\\ne$ 0 indicates the station is away from the corresponding location. <br /> <br />\n",
      "    \n",
      "So, for a given station (stn1), we look for the station(stn2) which minimizes |id(stn2) - id(stn1)|. \n",
      "</font>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "GSOD_Stations = GSOD_Stations.groupby(GSOD_Stations.index).first() #removing duplicate station ids \n",
      "GSOD_Stations['flag'] = 0 #flag=0 for 'good' data\n",
      "for stn in gsod_stations_absent:\n",
      "    if(stn in GSOD_Stations.index): continue\n",
      "    (_, stn_close) =  min(enumerate(GSOD_Stations.index.tolist()), key=lambda x: abs(int(x[1])- int(stn)))\n",
      "    df_temp = GSOD_Stations.loc[str(stn_close),:]\n",
      "    df_temp.name, df_temp.flag = stn, 1\n",
      "    GSOD_Stations = GSOD_Stations.append(df_temp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/ubuntu/anaconda/lib/python2.7/site-packages/pandas/core/generic.py:1830: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_index,col_indexer] = value instead\n",
        "  self[name] = value\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font face='\"Lucida Console\", Monaco, monospace' color = 'navy'> \n",
      "Removing unncessary station data from dataframes\n",
      "</font>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "GHCN_Stations = GHCN_Stations.loc[ghcn_counts.keys(),:]\n",
      "GSOD_Stations = GSOD_Stations.loc[gsod_counts.keys(),:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font face='\"Lucida Console\", Monaco, monospace' color = 'navy'> \n",
      "Defining some variables required for the analysis\n",
      "</font>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#sort indices to speed up finding indices of stations through binary seaching\n",
      "GHCN_Stations = GHCN_Stations.sort_index()\n",
      "GSOD_Stations = GSOD_Stations.sort_index()\n",
      "\n",
      "ghcn_stations   = np.array(GHCN_Stations.index)\n",
      "ghcn_latitudes  = np.array(GHCN_Stations['latitude'])\n",
      "ghcn_longitudes = np.array(GHCN_Stations['longitude'])\n",
      "\n",
      "gsod_stations   = np.array(GSOD_Stations.index)\n",
      "gsod_latitudes  = np.array(GSOD_Stations['LAT'])\n",
      "gsod_longitudes = np.array(GSOD_Stations['LON'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#can be converted to sparse matrices but the size if not large\n",
      "def construct_counts_matrix(counts, stations, range_years, min_year, measurements):\n",
      "    S = np.zeros((len(measurements), stations.size, range_years), dtype=int)\n",
      "    for stn in counts.iterkeys():\n",
      "        stn_id = np.searchsorted(stations,stn)\n",
      "        for (yr,meas) in counts[stn].iterkeys():\n",
      "            if(meas in measurements):\n",
      "                meas_id = measurements.index(meas)\n",
      "                S[meas_id,stn_id, yr-min_year] = counts[stn][(yr,meas)]\n",
      "    return S\n",
      "\n",
      "ghcn_counts_matrix = construct_counts_matrix(ghcn_counts, ghcn_stations, ghcn_range_years, ghcn_min_year, ghcn_measurements)\n",
      "gsod_counts_matrix = construct_counts_matrix(gsod_counts, gsod_stations, gsod_range_years, gsod_min_year, gsod_measurements)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "MemoryError",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-25-50e4695662c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mghcn_counts_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstruct_counts_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mghcn_counts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mghcn_stations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mghcn_range_years\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mghcn_min_year\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mghcn_measurements\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mgsod_counts_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstruct_counts_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgsod_counts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgsod_stations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgsod_range_years\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgsod_min_year\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgsod_measurements\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-25-50e4695662c8>\u001b[0m in \u001b[0;36mconstruct_counts_matrix\u001b[1;34m(counts, stations, range_years, min_year, measurements)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#can be converted to sparse matrices but the size if not large\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mconstruct_counts_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange_years\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_year\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeasurements\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeasurements\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange_years\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mstn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcounts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mstn_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mMemoryError\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Temporal Evolution of Station Networks"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def find_evolution_stats(count_matrix, len_meas , range_years):\n",
      "    evolution_data = np.zeros((len_meas+1,range_years))\n",
      "    for i in range(len_meas):\n",
      "        evolution_data[i] = np.sum(count_matrix[i] > 0, axis = 0) \n",
      "\n",
      "    evolution_data[len_meas] = np.sum((count_matrix[0] + count_matrix[1]) > 0, axis = 0) #Check for either TMIN/TMAX to be present\n",
      "    return evolution_data      \n",
      "\n",
      "ghcn_evolution_data = find_evolution_stats(ghcn_counts_matrix, len(ghcn_measurements) , ghcn_range_years)\n",
      "gsod_evolution_data = find_evolution_stats(gsod_counts_matrix, len(gsod_measurements) , gsod_range_years)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_evolution (min_year, max_year, evolution_data, measurements, dataset):\n",
      "    fig=plt.figure(1,figsize=[12,9],dpi=300)\n",
      "    suptitle('Time series of the number of stations w.r.t different measurements ' + dataset, fontsize=13)\n",
      "    for i in range(4):\n",
      "        subplot(2,2,i+1)\n",
      "        plot(range(min_year, max_year+1), evolution_data[5 if i==0 else i+1], c = 'forestgreen')\n",
      "        xlabel('year'); ylabel('Number of Stations')\n",
      "        xlim(min_year-10, max_year+5)\n",
      "        ylim(0,50000) if dataset == 'GHCN-D' else ylim(0,25000)\n",
      "        title(measurements[i+1] + ('' if i>0 else ' / ' + measurements[i])  )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_evolution(ghcn_min_year, ghcn_max_year, ghcn_evolution_data, ghcn_measurements, 'GHCN-D')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_evolution(gsod_min_year, gsod_max_year, gsod_evolution_data, gsod_measurements, 'GSOD')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font face='\"Lucida Console\", Monaco, monospace' color = 'navy'> \n",
      "We can observe that in GHCN-D dataset, there are many stations which are just collecting PRCP data. In GSOD, stations seem to cover  all the measurements as the plots follow a similar trend.<br /> \n",
      "Also GHCN-D covers more stations than GSOD. \n",
      "</font>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Missing data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#this code is not efficient. to be improved...\n",
      "def find_missing_data(counts, len_meas, measurements):\n",
      "    missing_data = np.zeros((len_meas-1,6))\n",
      "    for stn in counts.keys():\n",
      "        for (yr,meas) in counts[stn].keys():\n",
      "            if(meas in measurements):\n",
      "                idx = max(measurements.index(meas)-1, 0) #TMAX, TMIN are considered the same\n",
      "                loc = min(10*(365 - counts[stn][(yr,meas)])/365 , 5)\n",
      "                missing_data[idx, loc] += 1\n",
      "    return missing_data         \n",
      "ghcn_missing_data = find_missing_data(ghcn_counts, len(ghcn_measurements) , ghcn_measurements)\n",
      "gsod_missing_data = find_missing_data(gsod_counts, len(gsod_measurements) , gsod_measurements)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_missing(missing_data, measurements, dataset):\n",
      "    fig=plt.figure(1,figsize=[14,10],dpi=300)\n",
      "    suptitle('% of missing data w.r.t different measurements ' + dataset, fontsize=13)\n",
      "    for i in range(4):\n",
      "        ax = fig.add_subplot(2,2,i+1)\n",
      "        bar(range(6), missing_data[i]/np.sum(missing_data[i]), color = 'forestgreen')\n",
      "        xlabel('percent of record missing in an entry'); ylabel('ratio of yearly records present');\n",
      "        title(measurements[i+1] + ('' if i>0 else ' / ' + measurements[i]))\n",
      "        ylim(0,1)\n",
      "        ax.set_xticklabels(['<10','10-20', '20-30', '30-40', '40-50', '>50'])\n",
      "        ax.set_xticks(np.arange(6) + 0.35)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_missing(ghcn_missing_data, ghcn_measurements, 'GHCN-D')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_missing(gsod_missing_data, gsod_measurements, 'GSOD')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font face='\"Lucida Console\", Monaco, monospace' color = 'navy'> \n",
      "GSOD data seems to have lot of missing data. <br /><br />\n",
      "Interestingly, precipitation and temparature data have a similar trend in all of the plots. This may be because of the corruption of the data by a few sparse years. It might be a good idea to compare data only for years after 1950. <font color ='black'>(to be done...) </font>\n",
      "</font>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Length of record in years (min. 50% data avaialable)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#this code is not efficient. to be improved...\n",
      "def find_valid_data(counts, stations, measurements, threshold = 180):\n",
      "    valid_data = np.zeros((6,stations.size))\n",
      "    \n",
      "    temp_valid_years = dict([(stn,[]) for stn in stations]) #store valid years for which both TMIN and TMAX are available\n",
      "    \n",
      "    for stn in counts.iterkeys():\n",
      "        stn_id = np.searchsorted(stations,stn)\n",
      "        year_set = set([]) \n",
      "\n",
      "        for (yr,meas) in counts[stn].iterkeys():\n",
      "            if(meas in measurements):        \n",
      "                if(counts[stn][(yr,meas)] > threshold):\n",
      "                    idx = measurements.index(meas)\n",
      "                    valid_data[idx,stn_id]+=1\n",
      "                    if(meas=='TMIN' or meas=='TMAX'):   year_set.add(yr)\n",
      "\n",
      "\n",
      "        #this computes the number of valid years for which both TMIN and TMAX readings are available for the station\n",
      "        for yr in year_set:\n",
      "            mx_cnt = counts[stn][(yr, 'TMAX')] if counts[stn].has_key((yr, 'TMAX')) else 0\n",
      "            mn_cnt = counts[stn][(yr, 'TMIN')] if counts[stn].has_key((yr, 'TMIN')) else 0\n",
      "            if(mx_cnt>threshold and mn_cnt>threshold): \n",
      "                valid_data[5,stn_id] += 1 \n",
      "                temp_valid_years[stn].append(yr) \n",
      "\n",
      "    return (valid_data, temp_valid_years)\n",
      "     \n",
      "(ghcn_valid_data, ghcn_temp_valid_years)  = find_valid_data(ghcn_counts, ghcn_stations, ghcn_measurements)\n",
      "(gsod_valid_data, gsod_temp_valid_years)  = find_valid_data(gsod_counts, gsod_stations, gsod_measurements)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_missing(valid_data, measurements, range_years, dataset):\n",
      "    fig=plt.figure(1,figsize=[14,10],dpi=300)\n",
      "    suptitle('Valid records w.r.t different measurements '+dataset , fontsize=13)\n",
      "    for i in range(4):\n",
      "        ax = fig.add_subplot(2,2,i+1)\n",
      "        if(dataset == 'GHCN-D'):\n",
      "            bins = [0,20,40,60,80,100, range_years]\n",
      "            ax.set_xticklabels(['<20','20-40', '40-60', '60-80', '80-100', '>100'])\n",
      "        else : \n",
      "            bins = [0,20,40,range_years]\n",
      "            ax.set_xticklabels(['<20','20-40', '>40'])\n",
      "        \n",
      "        hist, bins = np.histogram(valid_data[5 if i==0 else i+1],  bins = bins)\n",
      "        bar(range(len(bins) - 1), hist, color = 'forestgreen' )\n",
      "        xlabel('Number of years with atleast 50% data'); ylabel('number of stations');\n",
      "        title(measurements[i+1] + ('' if i>0 else ' & ' + measurements[i]))\n",
      "        ylim(0,80000) if dataset == 'GHCN-D' else ylim(0,25000)\n",
      "        ax.set_xticks(np.arange(len(bins)) + 0.35)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_missing(ghcn_valid_data, ghcn_measurements, ghcn_range_years, 'GHCN-D')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_missing(gsod_valid_data, gsod_measurements, gsod_range_years, 'GSOD')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font face='\"Lucida Console\", Monaco, monospace' color = 'black'>\n",
      "References: <br />\n",
      "1.  http://www1.ncdc.noaa.gov/pub/data/ghcn/daily/papers/menne-etal2012.pdf<br />\n",
      "2.  http://cdiac.ornl.gov/ftp/ndp041/ndp041.pdf \n",
      "</font>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "GSOD_Stations['TEMP_RANGE_CNT'] = 0\n",
      "for stn in gsod_temp_valid_years:\n",
      "    GSOD_Stations['TEMP_RANGE_CNT'][stn] = len(gsod_temp_valid_years[stn])\n",
      "GSOD_Stations['PRCP_CNT'] = np.sum(gsod_counts_matrix[2] >180, axis = 1)\n",
      "GSOD_Stations['TEMP_CNT'] = np.sum(gsod_counts_matrix[4] >180, axis = 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "to_delete = GSOD_Stations['TEMP_RANGE_CNT'] + GSOD_Stations['PRCP_CNT'] + GSOD_Stations['TEMP_CNT'] == 0\n",
      "GSOD_Stations_2 = GSOD_Stations[~to_delete]\n",
      "to_delete = GSOD_Stations['TEMP_RANGE_CNT'] + GSOD_Stations['PRCP_CNT'] + GSOD_Stations['TEMP_CNT'] == 0\n",
      "GSOD_Stations_2 = GSOD_Stations[~to_delete]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cpkl.dump(GSOD_Stations_2, open( \"gsod_stations_cleaned\", \"wb\" ))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "GSOD_Stations.head(5)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print to_delete"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}